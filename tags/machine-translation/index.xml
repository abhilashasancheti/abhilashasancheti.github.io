<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine translation on Desh Raj</title>
    <link>https://desh2608.github.io/tags/machine-translation/</link>
    <description>Recent content in Machine translation on Desh Raj</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Thu, 14 Dec 2017 13:39:30 +0530</lastBuildDate>
    
	<atom:link href="https://desh2608.github.io/tags/machine-translation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Unsupervised Approaches for NMT</title>
      <link>https://desh2608.github.io/post/unsupervised-approaches-for-nmt/</link>
      <pubDate>Thu, 14 Dec 2017 13:39:30 +0530</pubDate>
      
      <guid>https://desh2608.github.io/post/unsupervised-approaches-for-nmt/</guid>
      <description>Translation is one of those tasks in language where the arrival of deep learning systems, and in particular sequence-to-sequence, has been something like a boon. In less than 4 years since the first paper on Neural Machine Translation, software giants such as Google and Microsoft have already announced that their translation systems have almost completely shifted from statistical to neural. Gone are the days when researchers mulled over complex word and phrase alignment techniques, and yet fell short on several language combinations.</description>
    </item>
    
    <item>
      <title>Metrics for NLG Evaluation</title>
      <link>https://desh2608.github.io/post/metrics-for-nlg-evaluation/</link>
      <pubDate>Sat, 16 Sep 2017 09:15:44 +0530</pubDate>
      
      <guid>https://desh2608.github.io/post/metrics-for-nlg-evaluation/</guid>
      <description>Simple natural language processing tasks such as sentiment analysis, or even more complex ones like semantic parsing are easy to evaluate since the evaluation simply requires label matching. As such, metrics like F-score (which is the harmonic mean of precision and recall), or even accuracy in uniformly distributed data, are used for such tasks.
Evaluating natural language generation systems is a much more complex task, however. And for this reason, a number of different metrics have been proposed for tasks such as machine translation or summarization.</description>
    </item>
    
  </channel>
</rss>